import pandas as pd
from sqlalchemy import create_engine

# Step 1: Define your Redshift connection using SQLAlchemy
def get_redshift_engine():
    engine = create_engine('postgresql+psycopg2://username:password@host:port/dbname')
    return engine

# Step 2: Load your table data into pandas DataFrame
def load_data_from_redshift(engine):
    query = "SELECT * FROM tickets_data;"  # Replace with your actual query
    df = pd.read_sql(query, engine)
    return df

# Step 3: Calculate max, mean, avg per ticket ID
def calculate_aggregates(df):
    aggregates = df.groupby('unique_ip_ticket_id')['Reopen_Deltas_int'].agg(
        max_value='max',
        mean_value='mean',
        avg_value='mean'  # avg is usually the same as mean in statistics
    ).reset_index()
    return aggregates

# Step 4: Update Redshift with the calculated values
def update_redshift(engine, aggregates):
    # First, merge the aggregates back into the Redshift table or use this for updating
    for _, row in aggregates.iterrows():
        update_query = f"""
        UPDATE tickets_data
        SET max_value = {row['max_value']},
            mean_value = {row['mean_value']},
            avg_value = {row['avg_value']}
        WHERE unique_ip_ticket_id = '{row['unique_ip_ticket_id']}';
        """
        with engine.connect() as conn:
            conn.execute(update_query)

# Step 5: Execute the steps
if __name__ == "__main__":
    # Connect to Redshift
    engine = get_redshift_engine()

    # Load data
    df = load_data_from_redshift(engine)

    # Calculate aggregates
    aggregates = calculate_aggregates(df)

    # Update Redshift with new columns
    update_redshift(engine, aggregates)

    print("Redshift table updated successfully!")
