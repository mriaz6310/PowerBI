
import pandas as pd

def descriptive_stats_per_ticket(dataframe):
    # Define an empty list to store the results
    results = []

    # Group the dataframe by 'unique_ticket_id'
    grouped = dataframe.groupby( 'unique_ticket_id')

    # Iterate over each ticket ID and calculate the statistics
    for ticket_id, group in grouped:
        # Number of reopenings
        reopenings = group[group['Event_Type'] == 'IP-Level Ticket Reopened']
        count_reopen = reopenings['Event_Type'].count()
        
        # Percentage of Reopenings
        reopening_pct = reopenings['unique_ticket_id'].nunique() / group['unique_ticket_id'].nunique()
        
        # Mean
        days_mean = group['Reopen_Deltas_int'].mean()
        
        # Standard Deviation
        days_sd = group['Reopen_Deltas_int'].std()
        
        # Median
        days_median = group['Reopen_Deltas_int'].median()
        
        # Min and Max
        reopen_min = group['Reopen_Deltas_int'].min()
        reopen_max = group['Reopen_Deltas_int'].max()
        
        # Quartiles
        lower_bound_pct = group['Reopen_Deltas_int'].quantile(0.25)
        upper_bound_pct = group['Reopen_Deltas_int'].quantile(0.75)
        
        # 5th and 95th Percentiles
        five_lower_bound_pct = group['Reopen_Deltas_int'].quantile(0.05)
        ninety_five_upper_bound_pct = group['Reopen_Deltas_int'].quantile(0.95)
        
        # Append the results for this ticket ID as a dictionary
        results.append({
            'Ticket ID': ticket_id,
            'Total Number of Reopenings': count_reopen,
            '% of Reopenings': round(reopening_pct * 100, 2),
            'Mean': round(days_mean, 2),
            'SD': round(days_sd, 2),
            'Median': round(days_median, 2),
            'Min': round(reopen_min, 2),
            'Max': round(reopen_max, 2),
            '25th Percentile': round(lower_bound_pct, 2),
            '75th Percentile': round(upper_bound_pct, 2),
            '5th Percentile': round(five_lower_bound_pct, 2),
            '95th Percentile': round(ninety_five_upper_bound_pct, 2)
        })

    # Convert the list of results into a DataFrame
    stats_df = pd.DataFrame(results)
    
    return stats_df



import pandas as pd

def descriptive_stats_per_ticket(dataframe):
    # Define an empty list to store the results
    results = []

    # Group the dataframe by 'unique_ticket_id'
    grouped = dataframe.groupby('unique_ticket_id')

    # Iterate over each ticket ID and calculate the statistics
    for ticket_id, group in grouped:
        # Number of reopenings
        reopenings = group[group['Event_Type'] == 'IP-Level Ticket Reopened']
        count_reopen = reopenings['Event_Type'].count()
        
        # Percentage of Reopenings
        reopening_pct = reopenings['unique_ticket_id'].nunique() / group['unique_ticket_id'].nunique()
        
        # Mean
        days_mean = group['Reopen_Deltas_int'].mean()
        
        # Standard Deviation
        days_sd = group['Reopen_Deltas_int'].std()
        
        # Median
        days_median = group['Reopen_Deltas_int'].median()
        
        # Min and Max
        reopen_min = group['Reopen_Deltas_int'].min()
        reopen_max = group['Reopen_Deltas_int'].max()
        
        # Quartiles
        lower_bound_pct = group['Reopen_Deltas_int'].quantile(0.25)
        upper_bound_pct = group['Reopen_Deltas_int'].quantile(0.75)
        
        # 5th and 95th Percentiles
        five_lower_bound_pct = group['Reopen_Deltas_int'].quantile(0.05)
        ninety_five_upper_bound_pct = group['Reopen_Deltas_int'].quantile(0.95)
        
        # Append the results for this ticket ID as a dictionary
        results.append({
            'Ticket ID': ticket_id,
            'Total Number of Reopenings': count_reopen,
            '% of Reopenings': round(reopening_pct * 100, 2),
            'Mean': round(days_mean, 2),
            'SD': round(days_sd, 2),
            'Median': round(days_median, 2),
            'Min': round(reopen_min, 2),
            'Max': round(reopen_max, 2),
            '25th Percentile': round(lower_bound_pct, 2),
            '75th Percentile': round(upper_bound_pct, 2),
            '5th Percentile': round(five_lower_bound_pct, 2),
            '95th Percentile': round(ninety_five_upper_bound_pct, 2)
        })

    # Convert the list of results into a DataFrame
    stats_df = pd.DataFrame(results)
    
    return stats_df


result_df = descriptive_stats_per_ticket(your_dataframe)
print(result_df)


import os
from datetime import datetime

# Define the directory containing the log files
log_directory = './logs'  # Change to the actual log directory
master_log_file = 'master_log.txt'

# Define time limits
max_time_seconds = 3600  # 1 hour
min_time_seconds = 600   # 10 minutes

# Helper function to read log files and get start/end times
def get_execution_time(log_file):
    try:
        with open(log_file, 'r') as file:
            lines = file.readlines()
            # Assuming log format has start and end timestamps
            # Example: Start: 2024-09-09 10:00:00, End: 2024-09-09 10:30:45
            start_time_str = lines[0].strip().split(": ")[1]
            end_time_str = lines[1].strip().split(": ")[1]
            
            start_time = datetime.strptime(start_time_str, "%Y-%m-%d %H:%M:%S")
            end_time = datetime.strptime(end_time_str, "%Y-%m-%d %H:%M:%S")
            
            return (end_time - start_time).total_seconds()
    except Exception as e:
        return None

# Create or open the master log file for writing
with open(master_log_file, 'w') as master_log:
    # Write the header for the master log
    master_log.write("Script Name | Status       | Execution Time (seconds)\n")
    master_log.write("-" * 55 + "\n")

    # Loop through each log file in the directory
    for log_file in os.listdir(log_directory):
        if log_file.endswith('.log'):  # Assuming log files have a .log extension
            script_name = log_file.replace('.log', '')
            log_file_path = os.path.join(log_directory, log_file)
            execution_time = get_execution_time(log_file_path)

            # Determine if the script completed successfully or not
            if execution_time is not None:
                if execution_time < min_time_seconds:
                    status = "Too Fast"
                elif min_time_seconds <= execution_time <= max_time_seconds:
                    status = "Success"
                else:
                    status = "Too Slow"
                master_log.write(f"{script_name} | {status:<12} | {execution_time:.2f} seconds\n")
            else:
                master_log.write(f"{script_name} | Error reading log | N/A\n")


