import subprocess
import os
import time
from datetime import datetime

# Paths to the actual scripts
scripts = [
    '/home/user/scripts/data_ingest.py',
    '/home/user/scripts/process_data.py',
    '/home/user/scripts/generate_report.py'
]

# Log directory
log_directory = '/home/user/logs'  # Update to the directory where logs are stored

# Master log file
master_log_file = '/home/user/logs/master_log.txt'  # Update to your actual path

# Helper function to check completion in log file
def check_completion(log_file):
    try:
        with open(log_file, 'r') as file:
            lines = file.readlines()
            # Assume the last line of the log indicates success or failure
            last_line = lines[-1].strip().lower()
            if "completed successfully" in last_line:  # Update this line based on your success message
                return "Success"
            else:
                return "Failure"
    except Exception as e:
        return f"Error reading log: {e}"

# Helper function to run a script and log its completion status
def run_script(script_name):
    log_file = os.path.join(log_directory, f'{os.path.basename(script_name).replace(".py", "")}.log')
    
    # Run the script
    try:
        print(f"Running {script_name}...")
        with open(log_file, 'w') as log_output:
            # Using subprocess to run the script and log the output
            result = subprocess.run(['python3', script_name], stdout=log_output, stderr=log_output)
        print(f"{script_name} finished with return code {result.returncode}")
        return check_completion(log_file)
    
    except Exception as e:
        return f"Error running {script_name}: {e}"

# Create or open the master log file for writing
with open(master_log_file, 'w') as master_log:
    # Write header for the master log
    master_log.write("Script Name | Status       | Completion Time\n")
    master_log.write("-" * 50 + "\n")

    # Loop through each script and run it
    for script in scripts:
        start_time = datetime.now()
        
        # Run the script and get completion status
        status = run_script(script)
        
        end_time = datetime.now()
        completion_time = (end_time - start_time).total_seconds()

        # Log the result in the master log
        master_log.write(f"{os.path.basename(script)} | {status:<12} | {completion_time:.2f} seconds\n")
        print(f"Logged result for {script} in master log.")



aws rds describe-db-instances --db-instance-identifier my-prod-db --query "DBInstances[0].AllocatedStorage"


aws rds describe-db-instances --query "DBInstances[?Endpoint.Address=='your-db-hostname'].DBInstanceIdentifier" --output text

aws rds describe-db-instances --db-instance-identifier my-prod-db

Invoke-Command -ComputerName ServerB -ScriptBlock {
    pg_dump -h localhost -U username -F c dbname > "C:\path\to\save\db_backup.dump"
} -Credential (Get-Credential)


ssh user@ServerB "pg_dump -h localhost -U username -F c dbname > /path/to/save/db_backup.dump"


# Check if OpenSSH Client is installed
Get-WindowsCapability -Online | Where-Object Name -like 'OpenSSH.Client*'

# If not installed, install it
Add-WindowsCapability -Online -Name OpenSSH.Client~~~~0.0.1.0





Pgdump users
pg_dumpall -U my_user -h my-db-host.example.com -p 5432 --globals-only > users_roles.sql :Users

All tables except one
pg_dump -U my_user -h my-db-host.example.com -p 5432 -d my_database -F c -T large_table -f backup.dump

Single table
pg_dump -U my_user -h my-db-host.example.com -p 5432 -d my_database -t large_table -F c -f large_table.dump
 The above will dump a table separately 

Restore users global
psql -U postgres -h new-db-host.example.com -p 5432 -f users_roles.sql

Restore table excluding large table 
pg_restore -U my_user -h new-db-host.example.com -p 5432 -d my_database -F c backup.dump


Restore large table separately:
pg_restore -U my_user -h new-db-host.example.com -p 5432 -d my_database -F c large_table.dump


$databases = psql -U my_user -h my-db-host.example.com -p 5432 -d postgres -t -c "SELECT datname FROM pg_database WHERE datname NOT IN ('template0', 'template1');"

foreach ($dbname in $databases) {
    $dbname = $dbname.Trim()
    $backupPath = "G:\Postgres_Backups\$dbname"
    
    # Create backup directory if it doesn't exist
    if (!(Test-Path $backupPath)) {
        New-Item -ItemType Directory -Path $backupPath | Out-Null
    }

    # Run pg_dump with 8 parallel jobs
    pg_dump -U my_user -h my-db-host.example.com -p 5432 -F d -j 8 -d $dbname -f $backupPath
}



